{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集和源代码可以在此处获得\n",
    "\n",
    "tutorials:https://github.com/dmlc/gluon-cv/tree/master/scripts/re-id/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#market1501.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import json, os\n",
    "from os import path as osp\n",
    "from zipfile import ZipFile\n",
    "from gluoncv.utils import download\n",
    "\n",
    "\n",
    "def extract(fpath, exdir):\n",
    "    print(\"Extracting zip file\")\n",
    "    with ZipFile(fpath) as z:\n",
    "        z.extractall(path=exdir)\n",
    "    print(\"Extracting Done\")\n",
    "\n",
    "def make_list(exdir):\n",
    "    train_dir = osp.join(exdir, \"bounding_box_train\")\n",
    "    train_list = {}\n",
    "    for _, _, files in os.walk(train_dir, topdown=False):\n",
    "        for name in files:\n",
    "            if '.jpg' in name:\n",
    "                name_split = name.split('_')\n",
    "                pid = name_split[0]\n",
    "                pcam = name_split[1][1]\n",
    "                if pid not in train_list:\n",
    "                    train_list[pid] = []\n",
    "                train_list[pid].append({\"name\":name, \"pid\":pid, \"pcam\":pcam})\n",
    "\n",
    "\n",
    "    with open(osp.join(exdir, 'train.txt'), 'w') as f:\n",
    "        for i, key in enumerate(train_list):\n",
    "            for item in train_list[key]:\n",
    "                f.write(item['name']+\" \"+str(i)+\" \"+item[\"pcam\"]+\"\\n\")\n",
    "    print(\"Make Label List Done\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    name = \"Market-1501-v15.09.15\"\n",
    "    url = \"http://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/\"+name+\".zip\"\n",
    "    root = osp.expanduser(\"~/.mxnet/datasets\")\n",
    "    if not os.path.exists(root):\n",
    "        os.mkdir(root)\n",
    "    fpath = osp.join(root, name+'.zip')\n",
    "    exdir = osp.join(root, name)\n",
    "\n",
    "    if os.path.exists(fpath):\n",
    "        if not osp.isdir(exdir):\n",
    "            extract(fpath, root)\n",
    "            make_list(exdir)\n",
    "            \n",
    "    else:\n",
    "        download(url, fpath, False)\n",
    "        extract(fpath, root)\n",
    "        make_list(exdir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python market1501.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.py\n",
    "from __future__ import division\n",
    "\n",
    "import argparse, datetime, os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet import autograd\n",
    "\n",
    "from networks import resnet18, resnet34, resnet50\n",
    "from gluoncv.data.market1501.data_read import ImageTxtDataset\n",
    "from gluoncv.data.market1501.label_read import LabelList\n",
    "from gluoncv.data.transforms.block import RandomCrop\n",
    "\n",
    "\n",
    "\n",
    "# CLI\n",
    "parser = argparse.ArgumentParser(description='Train a model for image classification.')\n",
    "parser.add_argument('--img-height', type=int, default=384,\n",
    "                    help='the height of image for input')\n",
    "parser.add_argument('--img-width', type=int, default=128,\n",
    "                    help='the width of image for input')\n",
    "parser.add_argument('--batch-size', type=int, default=32,\n",
    "                    help='training batch size per device (CPU/GPU).')\n",
    "parser.add_argument('--num-workers', type=int, default=8,\n",
    "                    help='the number of workers for data loader')\n",
    "parser.add_argument('--dataset-root', type=str, default=\"~/.mxnet/datasets\",\n",
    "                    help='the number of workers for data loader')\n",
    "parser.add_argument('--dataset', type=str, default=\"market1501\",\n",
    "                    help='the number of workers for data loader')\n",
    "parser.add_argument('--num-gpus', type=int, default=1,\n",
    "                    help='number of gpus to use.')\n",
    "parser.add_argument('--warmup', type=bool, default=True,\n",
    "                    help='number of training epochs.')\n",
    "parser.add_argument('--epochs', type=str, default=\"5,25,50,75\")\n",
    "parser.add_argument('--ratio', type=float, default=1.,\n",
    "                    help=\"ratio of training set to all set\")\n",
    "parser.add_argument('--pad', type=int, default=10)\n",
    "parser.add_argument('--lr', type=float, default=3.5e-4,\n",
    "                    help='learning rate. default is 0.1.')\n",
    "parser.add_argument('-momentum', type=float, default=0.9,\n",
    "                    help='momentum value for optimizer, default is 0.9.')\n",
    "parser.add_argument('--wd', type=float, default=5e-4,\n",
    "                    help='weight decay rate. default is 5e-4.')\n",
    "parser.add_argument('--seed', type=int, default=613,\n",
    "                    help='random seed to use. Default=613.')\n",
    "parser.add_argument('--lr-decay', type=int, default=0.1)\n",
    "parser.add_argument('--hybridize', type=bool, default=True)\n",
    "\n",
    "\n",
    "def get_data_iters(batch_size):\n",
    "    train_set, val_set = LabelList(ratio=opt.ratio, root=opt.dataset_root, name=opt.dataset)\n",
    "\n",
    "    normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize(size=(opt.img_width, opt.img_height), interpolation=1),\n",
    "        transforms.RandomFlipLeftRight(),\n",
    "        RandomCrop(size=(opt.img_width, opt.img_height), pad=opt.pad),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer])\n",
    "\n",
    "    train_imgs = ImageTxtDataset(train_set, transform=transform_train)\n",
    "    train_data = gluon.data.DataLoader(train_imgs, batch_size, shuffle=True, last_batch='discard', num_workers=opt.num_workers)\n",
    "\n",
    "    if opt.ratio < 1:\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize(size=(opt.img_width, opt.img_height), interpolation=1),\n",
    "            transforms.ToTensor(),\n",
    "            normalizer])\n",
    "            \n",
    "        val_imgs = ImageTxtDataset(val_set, transform=transform_test)\n",
    "        val_data = gluon.data.DataLoader(val_imgs, batch_size, shuffle=True, last_batch='discard', num_workers=opt.num_workers)\n",
    "    else:\n",
    "        val_data = None\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "\n",
    "def validate(val_data, net, criterion, ctx):\n",
    "    loss = 0.0\n",
    "    for data, label in val_data:\n",
    "        data_list = gluon.utils.split_and_load(data, ctx)\n",
    "        label_list = gluon.utils.split_and_load(label, ctx)\n",
    "\n",
    "        with autograd.predict_mode():\n",
    "            outpus = [net(X) for X in data_list]\n",
    "            losses = [criterion(X, y) for X, y in zip(outpus, label_list)]\n",
    "        accuracy = [(X.argmax(axis=1)==y.astype('float32')).mean.asscalar() for X, y in zip(outpus, label_list)]\n",
    "\n",
    "        loss_list = [l.mean().asscalar() for l in losses]\n",
    "        loss += sum(loss_list) / len(loss_list)\n",
    "\n",
    "    return loss/len(val_data), sum(accuracy)/len(accuracy)\n",
    "\n",
    "\n",
    "def main(net, batch_size, epochs, opt, ctx):\n",
    "    train_data, val_data = get_data_iters(batch_size)\n",
    "    if opt.hybridize:\n",
    "        net.hybridize()\n",
    "\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': opt.lr, 'wd': opt.wd})\n",
    "    criterion = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    lr = opt.lr\n",
    "    if opt.warmup:\n",
    "        minlr = lr*0.01\n",
    "        dlr = (lr-minlr)/(epochs[0]-1)\n",
    "\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for epoch in range(epochs[-1]):\n",
    "        _loss = 0.\n",
    "        if opt.warmup:\n",
    "            if epoch<epochs[0]:\n",
    "                lr = minlr + dlr*epoch\n",
    "        if epoch in epochs[1:]:\n",
    "            lr = lr * opt.lr_decay\n",
    "        trainer.set_learning_rate(lr)\n",
    "\n",
    "        for data, label in train_data:\n",
    "            data_list = gluon.utils.split_and_load(data, ctx)\n",
    "            label_list = gluon.utils.split_and_load(label, ctx)\n",
    "            with autograd.record():\n",
    "                output = [net(X) for X in data_list]\n",
    "                losses = [criterion(X, y) for X, y in zip(output, label_list)]\n",
    "\n",
    "            for l in losses:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            _loss_list = [l.mean().asscalar() for l in losses]\n",
    "            _loss += sum(_loss_list) / len(_loss_list)\n",
    "\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        __loss = _loss/len(train_data)\n",
    "\n",
    "        if val_data is not None:\n",
    "            val_loss, val_accuracy = validate(val_data, net, criterion, ctx)\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, Val loss %f, Val accuracy %f, \" % (epoch, __loss , val_loss, val_accuracy))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train loss: %f, \" % (epoch, __loss))\n",
    "\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
    "\n",
    "    if not os.path.exists(\"params\"):\n",
    "        os.mkdir(\"params\")\n",
    "    net.save_parameters(\"params/resnet50.params\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    opt = parser.parse_args()\n",
    "    logging.info(opt)\n",
    "    mx.random.seed(opt.seed)\n",
    "\n",
    "    batch_size = opt.batch_size\n",
    "    num_gpus = opt.num_gpus\n",
    "    epochs = [int(i) for i in opt.epochs.split(',')]\n",
    "    batch_size *= max(1, num_gpus)\n",
    "\n",
    "    context = [mx.gpu(i) for i in range(num_gpus)]\n",
    "    net = resnet50(ctx=context, num_classes=751)\n",
    "    main(net, batch_size, epochs, opt, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/public/home/ztu/code/git/pycode/gluoncv/re-id\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-1251aff4-dcda-c142-af7f-c19a67ed88df)\r\n",
      "GPU 1: Tesla P100-PCIE-16GB (UUID: GPU-ae5cde47-bf7f-a6c6-8a68-8a3c96b2dadf)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 22 16:15:17 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:2F:00.0 Off |                    0 |\r\n",
      "| N/A   48C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   43C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(batch_size=32, dataset='market1501', dataset_root='~/.mxnet/datasets', epochs='5,25,50,75', hybridize=True, img_height=384, img_width=128, lr=0.00035, lr_decay=0.1, momentum=0.9, num_gpus=1, num_workers=8, pad=10, ratio=1.0, seed=613, warmup=True, wd=0.0005)\n",
      "[16:15:34] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "Epoch 0. Train loss: 6.597217, Time 00:01:38, lr 3.5e-06\n",
      "Epoch 1. Train loss: 4.248931, Time 00:01:32, lr 9.012500000000001e-05\n",
      "^C\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-8:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"baseline/train.py\", line 168, in <module>\n",
      "    main(net, batch_size, epochs, opt, context)\n",
      "  File \"baseline/train.py\", line 133, in main\n",
      "    _loss_list = [l.mean().asscalar() for l in losses]\n",
      "  File \"baseline/train.py\", line 133, in <listcomp>\n",
      "    _loss_list = [l.mean().asscalar() for l in losses]\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\", line 2014, in asscalar\n",
      "    return self.asnumpy()[0]\n",
      "  File \"/public/home/ztu/app/anaconda3/envs/gluoncv/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\", line 1996, in asnumpy\n",
      "    ctypes.c_size_t(data.size)))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python baseline/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实我早就训练好了...\n",
    "\n",
    "所以就省略gpu跑训练代码的输出过程\n",
    "\n",
    "下面直接上测试代码吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.py\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from networks import resnet18, resnet34, resnet50\n",
    "from gluoncv.data.market1501.data_read import ImageTxtDataset\n",
    "\n",
    "import time, os, sys\n",
    "import scipy.io as sio\n",
    "from os import path as osp\n",
    "\n",
    "def get_data(batch_size, test_set, query_set):\n",
    "    normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(size=(128, 384), interpolation=1),\n",
    "        transforms.ToTensor(),\n",
    "        normalizer])\n",
    "\n",
    "    test_imgs = ImageTxtDataset(test_set, transform=transform_test)\n",
    "    query_imgs = ImageTxtDataset(query_set, transform=transform_test)\n",
    "\n",
    "    test_data = gluon.data.DataLoader(test_imgs, batch_size, shuffle=False, last_batch='keep', num_workers=8)\n",
    "    query_data = gluon.data.DataLoader(query_imgs, batch_size, shuffle=False, last_batch='keep', num_workers=8)\n",
    "    return test_data, query_data\n",
    "\n",
    "\n",
    "def load_network(network, ctx):\n",
    "    network.load_parameters('params/resnet50.params', ctx=ctx, allow_missing=True, ignore_extra=True)\n",
    "    return network\n",
    "\n",
    "\n",
    "def fliplr(img):\n",
    "    '''flip horizontal'''\n",
    "    img_flip = nd.flip(img, axis=3)\n",
    "    return img_flip\n",
    "\n",
    "\n",
    "def extract_feature(model, dataloaders, ctx):\n",
    "    count = 0\n",
    "    features = []\n",
    "    for img, _ in dataloaders:\n",
    "        n = img.shape[0]\n",
    "        count += n\n",
    "        print(count)\n",
    "        ff = np.zeros((n, 2048))\n",
    "        for i in range(2):\n",
    "            if(i==1):\n",
    "                img = fliplr(img)\n",
    "            f = model(img.as_in_context(ctx)).as_in_context(mx.cpu()).asnumpy()\n",
    "            ff = ff+f\n",
    "        features.append(ff)\n",
    "    features = np.concatenate(features)\n",
    "    return features/np.linalg.norm(features, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def get_id(img_path):\n",
    "    cameras = []\n",
    "    labels = []\n",
    "    for path in img_path:\n",
    "        cameras.append(int(path[0].split('/')[-1].split('_')[1][1]))\n",
    "        labels.append(path[1])\n",
    "    return np.array(cameras), np.array(labels)\n",
    "\n",
    "\n",
    "def compute_mAP(index, good_index, junk_index):\n",
    "    ap = 0\n",
    "    cmc = np.zeros(len(index))\n",
    "    if good_index.size==0:   # if empty\n",
    "        cmc[0] = -1\n",
    "        return ap,cmc\n",
    "\n",
    "    # remove junk_index\n",
    "    mask = np.in1d(index, junk_index, invert=True)\n",
    "    index = index[mask]\n",
    "\n",
    "    # find good_index index\n",
    "    ngood = len(good_index)\n",
    "    mask = np.in1d(index, good_index)\n",
    "    rows_good = np.argwhere(mask==True)\n",
    "    rows_good = rows_good.flatten()\n",
    "    \n",
    "    cmc[rows_good[0]:] = 1\n",
    "    for i in range(ngood):\n",
    "        d_recall = 1.0/ngood\n",
    "        precision = (i+1)*1.0/(rows_good[i]+1)\n",
    "        if rows_good[i]!=0:\n",
    "            old_precision = i*1.0/rows_good[i]\n",
    "        else:\n",
    "            old_precision=1.0\n",
    "        ap = ap + d_recall*(old_precision + precision)/2\n",
    "\n",
    "    return ap, cmc\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_size = 256\n",
    "    data_dir = osp.expanduser(\"~/.mxnet/datasets/Market-1501-v15.09.15/\")\n",
    "    gpu_ids = [0]\n",
    "\n",
    "    # set gpu ids\n",
    "    if len(gpu_ids)>0:\n",
    "        context = mx.gpu()\n",
    "\n",
    "    test_set = [(osp.join(data_dir,'bounding_box_test',line), int(line.split('_')[0])) for line in os.listdir(data_dir+'bounding_box_test') if \"jpg\" in line and \"-1\" not in line]\n",
    "    query_set = [(osp.join(data_dir,'query',line), int(line.split('_')[0])) for line in os.listdir(data_dir+'query') if \"jpg\" in line]\n",
    "    \n",
    "    test_cam, test_label = get_id(test_set)\n",
    "    query_cam, query_label = get_id(query_set)\n",
    "\n",
    "    ######################################################################\n",
    "    # Load Collected data Trained model\n",
    "    model_structure = resnet50(ctx=context, pretrained=False)\n",
    "    model = load_network(model_structure, context)\n",
    "\n",
    "    # Extract feature\n",
    "    test_loader, query_loader = get_data(batch_size, test_set, query_set)\n",
    "    print('start test')\n",
    "    test_feature = extract_feature(model, test_loader, context)\n",
    "    print('start query')\n",
    "    query_feature = extract_feature(model, query_loader, context)\n",
    "\n",
    "\n",
    "    query_feature = nd.array(query_feature).as_in_context(mx.gpu(0))\n",
    "    test_feature = nd.array(test_feature).as_in_context(mx.gpu(0))\n",
    "\n",
    "    num = query_label.size\n",
    "    dist_all = nd.linalg.gemm2(query_feature, test_feature, transpose_b=True)\n",
    "\n",
    "    CMC = np.zeros(test_label.size)\n",
    "    ap = 0.0\n",
    "    for i in range(num):\n",
    "        cam = query_cam[i]\n",
    "        label = query_label[i]\n",
    "        index = dist_all[i].argsort(is_ascend=False).as_in_context(mx.cpu()).asnumpy().astype(\"int32\")\n",
    "\n",
    "        query_index = np.argwhere(test_label==label)\n",
    "        camera_index = np.argwhere(test_cam==cam)\n",
    "\n",
    "        good_index = np.setdiff1d(query_index, camera_index, assume_unique=True)\n",
    "        junk_index = np.intersect1d(query_index, camera_index)\n",
    "    \n",
    "        ap_tmp, CMC_tmp = compute_mAP(index, good_index, junk_index)\n",
    "        CMC = CMC + CMC_tmp\n",
    "        ap += ap_tmp\n",
    "\n",
    "    CMC = CMC/num #average CMC\n",
    "    print('top1:%f top5:%f top10:%f mAP:%f'%(CMC[0],CMC[4],CMC[9],ap/num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start test\n",
      "256\n",
      "[16:25:25] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "512\n",
      "768\n",
      "1024\n",
      "1280\n",
      "1536\n",
      "1792\n",
      "2048\n",
      "2304\n",
      "2560\n",
      "2816\n",
      "3072\n",
      "3328\n",
      "3584\n",
      "3840\n",
      "4096\n",
      "4352\n",
      "4608\n",
      "4864\n",
      "5120\n",
      "5376\n",
      "5632\n",
      "5888\n",
      "6144\n",
      "6400\n",
      "6656\n",
      "6912\n",
      "7168\n",
      "7424\n",
      "7680\n",
      "7936\n",
      "8192\n",
      "8448\n",
      "8704\n",
      "8960\n",
      "9216\n",
      "9472\n",
      "9728\n",
      "9984\n",
      "10240\n",
      "10496\n",
      "10752\n",
      "11008\n",
      "11264\n",
      "11520\n",
      "11776\n",
      "12032\n",
      "12288\n",
      "12544\n",
      "12800\n",
      "13056\n",
      "13312\n",
      "13568\n",
      "13824\n",
      "14080\n",
      "14336\n",
      "14592\n",
      "14848\n",
      "15104\n",
      "15360\n",
      "15616\n",
      "15872\n",
      "15913\n",
      "start query\n",
      "256\n",
      "512\n",
      "768\n",
      "1024\n",
      "1280\n",
      "1536\n",
      "1792\n",
      "2048\n",
      "2304\n",
      "2560\n",
      "2816\n",
      "3072\n",
      "3328\n",
      "3368\n",
      "[16:27:09] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "top1:0.921021 top5:0.971793 top10:0.980701 mAP:0.794266\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python baseline/test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluoncv",
   "language": "python",
   "name": "gluoncv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
