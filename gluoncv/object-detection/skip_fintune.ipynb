{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "10. Skip Finetuning by reusing part of pre-trained model\n===========================================================\n\nThere is a dilemma that pre-trained public dataset detection models need finetuning\nbefore we can apply them to our interested domain.\nWhile it is still a chanllenging\ntask, in this tutorial we showcase a very interesting way to reuse pre-trained models.\n\nBasically, you can grab a GluonCV pre-trained detection model and reset classes to a subset of\ncoco categories, and it will be instantly ready to use without any tuning.\n\nFirst let's import some necessary libraries:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nimport gluoncv\nfrom gluoncv import model_zoo, data, utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a pretrained model\n-------------------------\n\nLet's get an Faster RCNN model trained on COCO\ndataset with ResNet-50 backbone.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net = model_zoo.get_model('faster_rcnn_resnet50_v1b_coco', pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-process an image\n--------------------\nSimilar to faster rcnn inference tutorial, we grab and preprocess a demo image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "im_fname = utils.download('https://github.com/dmlc/web-data/blob/master/' +\n                          'gluoncv/detection/biking.jpg?raw=true',\n                          path='biking.jpg')\nx, orig_img = data.transforms.presets.rcnn.load_test(im_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reset classes to exactly what we want\n-------------------------------------\nOriginal COCO model has 80 classes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('coco classes: ', net.classes)\nnet.reset_class(classes=['bicycle', 'backpack'], reuse_weights=['bicycle', 'backpack'])\n# now net has 2 classes as desired\nprint('new classes: ', net.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inference and display\n---------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "box_ids, scores, bboxes = net(x)\nax = utils.viz.plot_bbox(orig_img, bboxes[0], scores[0], box_ids[0], class_names=net.classes)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "More flexible mapping strategy for reusing old weights\n------------------------------------------------------\nWe also support dict for 1-to-1 class weights re-mapping\nSo we can take advantage of this to remap some categories\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net = model_zoo.get_model('faster_rcnn_resnet50_v1b_coco', pretrained=True)\nnet.reset_class(classes=['spaceship'], reuse_weights={'spaceship':'bicycle'})\nbox_ids, scores, bboxes = net(x)\nax = utils.viz.plot_bbox(orig_img, bboxes[0], scores[0], box_ids[0], class_names=net.classes)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same story for different models\n--------------------------------------------------------\nWe can apply this strategy to SSD, YOLO and Mask-RCNN models\nNow we can use mask rcnn and reset class to detect person only\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net = model_zoo.get_model('mask_rcnn_resnet50_v1b_coco', pretrained=True)\nnet.reset_class(classes=['person'], reuse_weights=['person'])\nids, scores, bboxes, masks = [xx[0].asnumpy() for xx in net(x)]\n\n# paint segmentation mask on images directly\nwidth, height = orig_img.shape[1], orig_img.shape[0]\nmasks, _ = utils.viz.expand_mask(masks, bboxes, (width, height), scores)\norig_img = utils.viz.plot_mask(orig_img, masks)\n\n# identical to Faster RCNN object detection\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(1, 1, 1)\nax = utils.viz.plot_bbox(orig_img, bboxes, scores, ids,\n                         class_names=net.classes, ax=ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feel excited?\n--------------\nStay tuned for more generalized detection models with much more category\nknowledges than COCO and Pascal VOC!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}