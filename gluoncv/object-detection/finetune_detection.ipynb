{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "08. Finetune a pretrained detection model\n============================================\n\nFine-tuning is commonly used approach to transfer previously trained model to a new dataset.\nIt is especially useful if the targeting new dataset is relatively small.\n\nFinetuning from pre-trained models can help reduce the risk of overfitting.\nFinetuned model may also generalizes better if the previously used dataset is in the similar domain of the new dataset.\n\nThis tutorial opens up a good approach for fine-tuning object detection models\nprovided by GluonCV.\nMore Specifically, we show how to use a customized Pikachu dataset and illustrate the finetuning fundamentals step by step.\nYou will be familiarize the steps and modify it to fit your own object detection projects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport mxnet as mx\nfrom mxnet import autograd, gluon\nimport gluoncv as gcv\nfrom gluoncv.utils import download, viz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pikachu Dataset\n----------------\nFirst we will start with a nice Pikachu dataset generated by rendering 3D models on random real-world scenes.\nYou can refer to `sphx_glr_build_examples_datasets_detection_custom.py` for tutorial of how to create your own datasets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "url = 'https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/train.rec'\nidx_url = 'https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/train.idx'\ndownload(url, path='pikachu_train.rec', overwrite=False)\ndownload(idx_url, path='pikachu_train.idx', overwrite=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can load dataset using ``RecordFileDetection``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = gcv.data.RecordFileDetection('pikachu_train.rec')\nclasses = ['pikachu']  # only one foreground class here\nimage, label = dataset[0]\nprint('label:', label)\n# display image and label\nax = viz.plot_bbox(image, bboxes=label[:, :4], labels=label[:, 4:5], class_names=classes)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-trained models\n-------------------\nNow we can grab a pre-trained model to finetune from. Here we have so many choices from `gluoncv-model-zoo-detection` Model Zoo.\nAgain for demo purpose, we choose a fast SSD network with MobileNet1.0 backbone.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_voc', pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "reset network to predict pikachus!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.reset_class(classes)\n# now the output layers that used to map to VOC classes are now reset to distinguish pikachu (and background)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is a convenient API for creating custom network with pre-trained weights.\nThis is equivalent to loading pre-trained model and call ``net.reset_class``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_custom', classes=classes,\n    pretrained_base=False, transfer='voc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By loading from fully pre-trained models, you are not only loading base network weights\n(mobilenet for example), but also some additional blocks for object detection specifically.\n\nPretrained model from detection task is more relevant and adaptive than ``pretrained_base``\nnetwork which is usually trained on ImageNet for image classification task.\n\nTherefore finetuning may converge significantly faster and better in some situations.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finetuning is a new round of training\n--------------------------------------\n.. hint::\n\n    You will find a more detailed training implementation of SSD here:\n    :download:`Download train_ssd.py<../../../scripts/detection/ssd/train_ssd.py>`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_dataloader(net, train_dataset, data_shape, batch_size, num_workers):\n    from gluoncv.data.batchify import Tuple, Stack, Pad\n    from gluoncv.data.transforms.presets.ssd import SSDDefaultTrainTransform\n    width, height = data_shape, data_shape\n    # use fake data to generate fixed anchors for target generation\n    with autograd.train_mode():\n        _, _, anchors = net(mx.nd.zeros((1, 3, height, width)))\n    batchify_fn = Tuple(Stack(), Stack(), Stack())  # stack image, cls_targets, box_targets\n    train_loader = gluon.data.DataLoader(\n        train_dataset.transform(SSDDefaultTrainTransform(width, height, anchors)),\n        batch_size, True, batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n    return train_loader\n\ntrain_data = get_dataloader(net, dataset, 512, 16, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try use GPU for training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    a = mx.nd.zeros((1,), ctx=mx.gpu(0))\n    ctx = [mx.gpu(0)]\nexcept:\n    ctx = [mx.cpu()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start training(finetuning)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.collect_params().reset_ctx(ctx)\ntrainer = gluon.Trainer(\n    net.collect_params(), 'sgd',\n    {'learning_rate': 0.001, 'wd': 0.0005, 'momentum': 0.9})\n\nmbox_loss = gcv.loss.SSDMultiBoxLoss()\nce_metric = mx.metric.Loss('CrossEntropy')\nsmoothl1_metric = mx.metric.Loss('SmoothL1')\n\nfor epoch in range(0, 2):\n    ce_metric.reset()\n    smoothl1_metric.reset()\n    tic = time.time()\n    btic = time.time()\n    net.hybridize(static_alloc=True, static_shape=True)\n    for i, batch in enumerate(train_data):\n        batch_size = batch[0].shape[0]\n        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n        cls_targets = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n        box_targets = gluon.utils.split_and_load(batch[2], ctx_list=ctx, batch_axis=0)\n        with autograd.record():\n            cls_preds = []\n            box_preds = []\n            for x in data:\n                cls_pred, box_pred, _ = net(x)\n                cls_preds.append(cls_pred)\n                box_preds.append(box_pred)\n            sum_loss, cls_loss, box_loss = mbox_loss(\n                cls_preds, box_preds, cls_targets, box_targets)\n            autograd.backward(sum_loss)\n        # since we have already normalized the loss, we don't want to normalize\n        # by batch-size anymore\n        trainer.step(1)\n        ce_metric.update(0, [l * batch_size for l in cls_loss])\n        smoothl1_metric.update(0, [l * batch_size for l in box_loss])\n        name1, loss1 = ce_metric.get()\n        name2, loss2 = smoothl1_metric.get()\n        if i % 20 == 0:\n            print('[Epoch {}][Batch {}], Speed: {:.3f} samples/sec, {}={:.3f}, {}={:.3f}'.format(\n                epoch, i, batch_size/(time.time()-btic), name1, loss1, name2, loss2))\n        btic = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save finetuned weights to disk\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.save_parameters('ssd_512_mobilenet1.0_pikachu.params')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predict with finetuned model\n----------------------------\nWe can test the performance using finetuned weights\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_url = 'https://raw.githubusercontent.com/zackchase/mxnet-the-straight-dope/master/img/pikachu.jpg'\ndownload(test_url, 'pikachu_test.jpg')\nnet = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_custom', classes=classes, pretrained_base=False)\nnet.load_parameters('ssd_512_mobilenet1.0_pikachu.params')\nx, image = gcv.data.transforms.presets.ssd.load_test('pikachu_test.jpg', 512)\ncid, score, bbox = net(x)\nax = viz.plot_bbox(image, bbox[0], score[0], cid[0], class_names=classes)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In two epochs and less than 5 min, we are able to detect pikachus perfectly!\n\n.. hint::\n\n    This finetune tutorial is not limited to SSD, you can extend it to Faster-RCNN, YOLO training by\n    adapting a training blocks in the following examples:\n\n    :download:`Download train_faster_rcnn.py<../../../scripts/detection/faster_rcnn/train_faster_rcnn.py>`\n    :download:`Download train_yolo3.py<../../../scripts/detection/yolo/train_yolo3.py>`\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}