{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Estimate pose from your webcam\n====================================\n\nThis article will demonstrate how to estimate people's pose from your webcam video stream.\n\n\nFirst, import the necessary modules.\n\n.. code-block:: python\n\n    from __future__ import division\n    import argparse, time, logging, os, math, tqdm, cv2\n\n    import numpy as np\n    import mxnet as mx\n    from mxnet import gluon, nd, image\n    from mxnet.gluon.data.vision import transforms\n\n    import matplotlib.pyplot as plt\n\n    import gluoncv as gcv\n    from gluoncv import data\n    from gluoncv.data import mscoco\n    from gluoncv.model_zoo import get_model\n    from gluoncv.data.transforms.pose import detector_to_simple_pose, heatmap_to_coord\n    from gluoncv.utils.viz import cv_plot_image, cv_plot_keypoints\n\n\nLoading the model and webcam\n----------------------------\n\nIn this tutorial we feed frames from the webcam into a detector, \nthen we estimate the pose for each detected people in the frame.\n\nFor the detector we use ``ssd_512_mobilenet1.0_coco`` as it is fast and accurate enough.\n\n\n.. code-block:: python\n\n    ctx = mx.cpu()\n    detector_name = \"ssd_512_mobilenet1.0_coco\"\n    detector = get_model(detector_name, pretrained=True, ctx=ctx)\n\n\nThe pre-trained model tries to detect all 80 classes of objects in an image,\nhowever in pose estimation we are only interested in one object class: person.\n\nTo speed up the detector, we can reset the prediction head to only include the classes we need.\n\n.. code-block:: python\n\n    detector.reset_class(classes=['person'], reuse_weights={'person':'person'})\n\n\nNext for the estimator, we choose ``simple_pose_resnet18_v1b`` for it is light-weighted.\n\nThe default ``simple_pose_resnet18_v1b`` model was trained with input size 256x192.\nWe also provide an optional ``simple_pose_resnet18_v1b`` model trained with input size 128x96.\nThe latter one is going to be faster, which means a smoother webcam demo.\nRemember that we can load an optional pre-trained model by passing its shasum to ``pretrained``.\n\n.. code-block:: python\n\n    estimator = get_model('simple_pose_resnet18_v1b', pretrained='ccd24037', ctx=ctx)\n\n\nWith OpenCV, we can easily retrieve frames from the webcam.\n\n.. code-block:: python\n\n    cap = cv2.VideoCapture(0)\n    time.sleep(1)  ### letting the camera autofocus\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In the code we run the demo on CPU, if your machine has a GPU then you may try heavier and more accurate\n    pre-trained detectors and estimators.\n    \n    For a list of models to choose from, please refer to our Model Zoo pages for detection and pose estimation.</p></div>\n\nEstimation loop \n--------------\n\nFor each frame, we perform the following steps:\n\n- loading the webcam frame\n- pre-process the image\n- detect people in the image\n- post-process the detected people\n- estimate the pose for each person\n- plot the result\n\n.. code-block:: python\n\n    axes = None\n    num_frames = 100\n\n    for i in range(num_frames):\n        ret, frame = cap.read()\n        frame = mx.nd.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).astype('uint8')\n\n        x, frame = gcv.data.transforms.presets.yolo.transform_test(frame, short=512, max_size=350)\n        x = x.as_in_context(ctx)\n        class_IDs, scores, bounding_boxs = detector(x)\n\n        pose_input, upscale_bbox = detector_to_simple_pose(frame, class_IDs, scores, bounding_boxs,\n                                                           output_shape=(128, 96), ctx=ctx)\n        if len(upscale_bbox) > 0:\n            predicted_heatmap = estimator(pose_input)\n            pred_coords, confidence = heatmap_to_coord(predicted_heatmap, upscale_bbox)\n\n            img = cv_plot_keypoints(frame, pred_coords, confidence, class_IDs, bounding_boxs, scores,\n                                    box_thresh=0.5, keypoint_thresh=0.2)\n        cv_plot_image(img)\n        cv2.waitKey(1)\n\n\nWe release the webcam before exiting:\n\n\n.. code-block:: python\n\n    cap.release()\n\nResults\n-------\n\nDownload the script to run the demo\n\n:download:`Download cam_demo.py<../../../scripts/pose/simple_pose/cam_demo.py>`\n\nRun the script \n\n.. code-block:: bash\n\n    python cam_demo.py --num-frames 100\n\n\nIf all goes well you should be able to see your pose detected!\n\n![](https://i.giphy.com/media/1kTFyZCOCA4yilyOHk/giphy.gif)\n\n\n\nThe input size significantly affect the inference speed.\nBelow is the webcam demo with input 256x192, compare the frames per second!\n\n![](https://i.giphy.com/media/8rFv0lvBgGf62CIcM7/giphy.gif)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}