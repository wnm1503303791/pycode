{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train Mask RCNN end-to-end on MS COCO\n",
    "===========================================\n",
    "\n",
    "This tutorial goes through the steps for training a Mask R-CNN [He17]_ instance segmentation model\n",
    "provided by GluonCV.\n",
    "\n",
    "Mask R-CNN is an extension to the Faster R-CNN [Ren15]_ object detection model.\n",
    "As such, this tutorial is also an extension to :doc:`../examples_detection/train_faster_rcnn_voc`.\n",
    "We will focus on the extra work on top of Faster R-CNN to show how to use GluonCV components\n",
    "to construct a Mask R-CNN model.\n",
    "\n",
    "It is highly recommended to read the original papers [Girshick14]_, [Girshick15]_, [Ren15]_, [He17]_\n",
    "to learn more about the ideas behind Mask R-CNN.\n",
    "Appendix from [He16]_ and experiment detail from [Lin17]_ may also be useful reference.\n",
    "\n",
    ".. hint::\n",
    "\n",
    "    Please first go through this `sphx_glr_build_examples_datasets_mscoco.py` tutorial to\n",
    "    setup MSCOCO dataset on your disk.\n",
    "\n",
    ".. hint::\n",
    "\n",
    "    You can skip the rest of this tutorial and start training your Mask RCNN model\n",
    "    right away by downloading this script:\n",
    "\n",
    "    :download:`Download train_mask_rcnn.py<../../../scripts/instance/mask_rcnn/train_mask_rcnn.py>`\n",
    "\n",
    "    Example usage:\n",
    "\n",
    "    Train a default resnet50_v1b model with COCO dataset on GPU 0:\n",
    "\n",
    "    .. code-block:: bash\n",
    "\n",
    "        python train_mask_rcnn.py --gpus 0\n",
    "\n",
    "    Train on GPU 0,1,2,3:\n",
    "\n",
    "    .. code-block:: bash\n",
    "\n",
    "        python train_mask_rcnn.py --gpus 0,1,2,3\n",
    "\n",
    "    Check the supported arguments:\n",
    "\n",
    "    .. code-block:: bash\n",
    "\n",
    "        python train_mask_rcnn.py --help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "-------\n",
    "\n",
    "Make sure COCO dataset has been set up on your disk.\n",
    "Then, we are ready to load training and validation images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data import COCOInstance\n",
    "\n",
    "# typically we use train2017 (i.e. train2014 + minival35k) split as training data\n",
    "# COCO dataset actually has images without any objects annotated,\n",
    "# which must be skipped during training to prevent empty labels\n",
    "train_dataset = COCOInstance(splits='instances_train2017', skip_empty=True)\n",
    "# and val2014 (i.e. minival5k) test as validation data\n",
    "val_dataset = COCOInstance(splits='instances_val2017', skip_empty=False)\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Validation images:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transform\n",
    "--------------\n",
    "We can read an (image, label, segm) tuple from the training dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label, train_segm = train_dataset[6]\n",
    "bboxes = train_label[:, :4]\n",
    "cids = train_label[:, 4:5]\n",
    "print('image:', train_image.shape)\n",
    "print('bboxes:', bboxes.shape, 'class ids:', cids.shape)\n",
    "# segm is a list of polygons which are arrays of points on the object boundary\n",
    "print('masks', [[poly.shape for poly in polys] for polys in train_segm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the image with boxes and labels:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from gluoncv.utils import viz\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax = viz.plot_bbox(train_image, bboxes, labels=cids, class_names=train_dataset.classes, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually see the object segmentation, we need to convert polygons to masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gluoncv.data.transforms import mask as tmask\n",
    "\n",
    "width, height = train_image.shape[1], train_image.shape[0]\n",
    "train_masks = np.stack([tmask.to_mask(polys, (width, height)) for polys in train_segm])\n",
    "plt_image = viz.plot_mask(train_image, train_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the image with boxes, labels and masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax = viz.plot_bbox(plt_image, bboxes, labels=cids, class_names=train_dataset.classes, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transforms, i.e. decoding and transformation, are identical to Faster R-CNN\n",
    "with the exception of segmentation polygons as an additional input.\n",
    ":py:class:`gluoncv.data.transforms.presets.rcnn.MaskRCNNDefaultTrainTransform`\n",
    "converts the segmentation polygons to binary segmentation mask.\n",
    ":py:class:`gluoncv.data.transforms.presets.rcnn.MaskRCNNDefaultValTransform`\n",
    "ignores the segmentation polygons and returns image tensor and ``[im_height, im_width, im_scale]``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short, max_size = 600, 1000  # resize image to short side 600 px, but keep maximum length within 1000\n",
    "train_transform = presets.rcnn.MaskRCNNDefaultTrainTransform(short, max_size)\n",
    "val_transform = presets.rcnn.MaskRCNNDefaultValTransform(short, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.random.seed(233)  # fix seed in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply transforms to train image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image2, train_label2, train_masks2 = train_transform(train_image, train_label, train_segm)\n",
    "print('tensor shape:', train_image2.shape)\n",
    "print('box and id shape:', train_label2.shape)\n",
    "print('mask shape', train_masks2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images in tensor are distorted because they no longer sit in (0, 255) range.\n",
    "Let's convert them back so we can see them clearly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_image2 = train_image2.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array(\n",
    "    (0.485, 0.456, 0.406))\n",
    "plt_image2 = (plt_image2 * 255).asnumpy().astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform already converted polygons to masks and we plot them directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = plt_image2.shape[1], plt_image2.shape[0]\n",
    "plt_image2 = viz.plot_mask(plt_image2, train_masks2)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax = viz.plot_bbox(plt_image2, train_label2[:, :4],\n",
    "                   labels=train_label2[:, 4:5],\n",
    "                   class_names=train_dataset.classes,\n",
    "                   ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader\n",
    "-----------\n",
    "Data loader is identical to Faster R-CNN with the difference of mask input and output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.data.batchify import Tuple, Append, MaskRCNNTrainBatchify\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 2  # for tutorial, we use smaller batch-size\n",
    "num_workers = 0  # you can make it larger(if your CPU has more cores) to accelerate data loading\n",
    "\n",
    "train_bfn = Tuple(*[Append() for _ in range(3)])\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=train_bfn, last_batch='rollover', num_workers=num_workers)\n",
    "val_bfn = Tuple(*[Append() for _ in range(2)])\n",
    "val_loader = DataLoader(val_dataset.transform(val_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=val_bfn, last_batch='keep', num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 3:\n",
    "        break\n",
    "    print('data 0:', batch[0][0].shape, 'label 0:', batch[1][0].shape, 'mask 0:', batch[2][0].shape)\n",
    "    print('data 1:', batch[0][1].shape, 'label 1:', batch[1][1].shape, 'mask 1:', batch[2][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask RCNN Network\n",
    "-------------------\n",
    "In GluonCV, Mask RCNN network :py:class:`gluoncv.model_zoo.MaskRCNN`\n",
    "is inherited from Faster RCNN network :py:class:`gluoncv.model_zoo.FasterRCNN`.\n",
    "\n",
    "`Gluon Model Zoo <../../model_zoo/index.html>`__ has some Mask RCNN pretrained networks.\n",
    "You can load your favorite one with one simple line of code:\n",
    "\n",
    ".. hint::\n",
    "\n",
    "   To avoid downloading models in this tutorial, we set ``pretrained_base=False``,\n",
    "   in practice we usually want to load pre-trained imagenet models by setting\n",
    "   ``pretrained_base=True``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import model_zoo\n",
    "\n",
    "net = model_zoo.get_model('mask_rcnn_resnet50_v1b_coco', pretrained_base=False)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask-RCNN has identical inputs but produces an additional output.\n",
    "``cids`` are the class labels,\n",
    "``scores`` are confidence scores of each prediction,\n",
    "``bboxes`` are absolute coordinates of corresponding bounding boxes.\n",
    "``masks`` are predicted segmentation masks corresponding to each bounding box\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "x = mx.nd.zeros(shape=(1, 3, 600, 800))\n",
    "net.initialize()\n",
    "cids, scores, bboxes, masks = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, an additional output is returned:\n",
    "``mask_preds`` are per class masks predictions\n",
    "in addition to ``cls_preds``, ``box_preds``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd\n",
    "\n",
    "with autograd.train_mode():\n",
    "    # this time we need ground-truth to generate high quality roi proposals during training\n",
    "    gt_box = mx.nd.zeros(shape=(1, 1, 4))\n",
    "    gt_label = mx.nd.zeros(shape=(1, 1, 1))\n",
    "    cls_pred, box_pred, mask_pred, roi, samples, matches, rpn_score, rpn_box, anchors, \\\n",
    "    cls_targets, box_targets, box_masks, indices = net(x, gt_box, gt_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training losses\n",
    "----------------\n",
    "There are one additional losses in Mask-RCNN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss to penalize incorrect foreground/background prediction\n",
    "rpn_cls_loss = mx.gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "# the loss to penalize inaccurate anchor boxes\n",
    "rpn_box_loss = mx.gluon.loss.HuberLoss(rho=1 / 9.)  # == smoothl1\n",
    "# the loss to penalize incorrect classification prediction.\n",
    "rcnn_cls_loss = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "# and finally the loss to penalize inaccurate proposals\n",
    "rcnn_box_loss = mx.gluon.loss.HuberLoss()  # == smoothl1\n",
    "# the loss to penalize incorrect segmentation pixel prediction\n",
    "rcnn_mask_loss = mx.gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training targets\n",
    "----------------\n",
    "RPN and RCNN training target are the same as in :doc:`../examples_detection/train_faster_rcnn_voc`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also push RPN targets computation to CPU workers, so network is passed to transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = presets.rcnn.MaskRCNNDefaultTrainTransform(short, max_size, net)\n",
    "# return images, labels, masks, rpn_cls_targets, rpn_box_targets, rpn_box_masks loosely\n",
    "batchify_fn = MaskRCNNTrainBatchify(net)\n",
    "# For the next part, we only use batch size 1\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask targets are generated with the intermediate outputs after rcnn target is generated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    with autograd.train_mode():\n",
    "        for data, label, masks, rpn_cls_targets, rpn_box_targets, rpn_box_masks in zip(*batch):\n",
    "            label = label.expand_dims(0)\n",
    "            gt_label = label[:, :, 4:5]\n",
    "            gt_box = label[:, :, :4]\n",
    "            # network forward\n",
    "            cls_pred, box_pred, mask_pred, roi, samples, matches, rpn_score, rpn_box, anchors, \\\n",
    "            cls_targets, box_targets, box_masks, indices = \\\n",
    "                net(data.expand_dims(0), gt_box, gt_label)\n",
    "\n",
    "            # generate targets for mask head\n",
    "            roi = mx.nd.concat(\n",
    "                *[mx.nd.take(roi[i], indices[i]) for i in range(indices.shape[0])], dim=0) \\\n",
    "                .reshape((indices.shape[0], -1, 4))\n",
    "            m_cls_targets = mx.nd.concat(\n",
    "                *[mx.nd.take(cls_targets[i], indices[i]) for i in range(indices.shape[0])], dim=0) \\\n",
    "                .reshape((indices.shape[0], -1))\n",
    "            matches = mx.nd.concat(\n",
    "                *[mx.nd.take(matches[i], indices[i]) for i in range(indices.shape[0])], dim=0) \\\n",
    "                .reshape((indices.shape[0], -1))\n",
    "            mask_targets, mask_masks = net.mask_target(roi, masks.expand_dims(0), matches,\n",
    "                                                       m_cls_targets)\n",
    "\n",
    "            print('data:', data.shape)\n",
    "            # box and class labels\n",
    "            print('box:', gt_box.shape)\n",
    "            print('label:', gt_label.shape)\n",
    "            # -1 marks ignored label\n",
    "            print('rpn cls label:', rpn_cls_targets.shape)\n",
    "            # mask out ignored box label\n",
    "            print('rpn box label:', rpn_box_targets.shape)\n",
    "            print('rpn box mask:', rpn_box_masks.shape)\n",
    "            # rcnn does not have ignored label\n",
    "            print('rcnn cls label:', cls_targets.shape)\n",
    "            # mask out ignored box label\n",
    "            print('rcnn box label:', box_targets.shape)\n",
    "            print('rcnn box mask:', box_masks.shape)\n",
    "            print('rcnn mask label:', mask_targets.shape)\n",
    "            print('rcnn mask mask:', mask_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop\n",
    "-------------\n",
    "After we have defined loss function and generated training targets, we can write the training loop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    with autograd.record():\n",
    "        for data, label, masks, rpn_cls_targets, rpn_box_targets, rpn_box_masks in zip(*batch):\n",
    "            label = label.expand_dims(0)\n",
    "            gt_label = label[:, :, 4:5]\n",
    "            gt_box = label[:, :, :4]\n",
    "            # network forward\n",
    "            cls_preds, box_preds, mask_preds, roi, samples, matches, rpn_score, rpn_box, anchors, \\\n",
    "                cls_targets, box_targets, box_masks, indices = \\\n",
    "                net(data.expand_dims(0), gt_box, gt_label)\n",
    "\n",
    "            # generate targets for mask head\n",
    "            roi = mx.nd.concat(\n",
    "                *[mx.nd.take(roi[i], indices[i]) for i in range(indices.shape[0])], dim=0) \\\n",
    "                .reshape((indices.shape[0], -1, 4))\n",
    "            m_cls_targets = mx.nd.concat(\n",
    "                *[mx.nd.take(cls_targets[i], indices[i]) for i in range(indices.shape[0])], dim=0) \\\n",
    "                .reshape((indices.shape[0], -1))\n",
    "            matches = mx.nd.concat(\n",
    "                *[mx.nd.take(matches[i], indices[i]) for i in range(indices.shape[0])], dim=0) \\\n",
    "                .reshape((indices.shape[0], -1))\n",
    "            mask_targets, mask_masks = net.mask_target(roi, masks.expand_dims(0), matches,\n",
    "                                                       m_cls_targets)\n",
    "\n",
    "            # losses of rpn\n",
    "            rpn_score = rpn_score.squeeze(axis=-1)\n",
    "            num_rpn_pos = (rpn_cls_targets >= 0).sum()\n",
    "            rpn_loss1 = rpn_cls_loss(rpn_score, rpn_cls_targets,\n",
    "                                     rpn_cls_targets >= 0) * rpn_cls_targets.size / num_rpn_pos\n",
    "            rpn_loss2 = rpn_box_loss(rpn_box, rpn_box_targets,\n",
    "                                     rpn_box_masks) * rpn_box.size / num_rpn_pos\n",
    "\n",
    "            # losses of rcnn\n",
    "            num_rcnn_pos = (cls_targets >= 0).sum()\n",
    "            rcnn_loss1 = rcnn_cls_loss(cls_preds, cls_targets,\n",
    "                                       cls_targets >= 0) * cls_targets.size / cls_targets.shape[\n",
    "                             0] / num_rcnn_pos\n",
    "            rcnn_loss2 = rcnn_box_loss(box_preds, box_targets, box_masks) * box_preds.size / \\\n",
    "                         box_preds.shape[0] / num_rcnn_pos\n",
    "\n",
    "            # loss of mask\n",
    "            mask_loss = rcnn_mask_loss(mask_preds, mask_targets, mask_masks) * mask_targets.size / \\\n",
    "                        mask_targets.shape[0] / mask_masks.sum()\n",
    "\n",
    "        # some standard gluon training steps:\n",
    "        # autograd.backward([rpn_loss1, rpn_loss2, rcnn_loss1, rcnn_loss2, mask_loss])\n",
    "        # trainer.step(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. hint::\n",
    "\n",
    "  Please checkout the full :download:`training script <../../../scripts/instance/mask_rcnn/train_mask_rcnn.py>` for complete implementation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------\n",
    "\n",
    ".. [Girshick14] Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik. Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation. CVPR 2014.\n",
    ".. [Girshick15] Ross Girshick. Fast {R-CNN}. ICCV 2015.\n",
    ".. [Ren15] Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun. Faster {R-CNN}: Towards Real-Time Object Detection with Region Proposal Networks. NIPS 2015.\n",
    ".. [He16] Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun. Deep Residual Learning for Image Recognition. CVPR 2016.\n",
    ".. [Lin17] Tsung-Yi Lin and Piotr Dollár and Ross Girshick and Kaiming He and Bharath Hariharan and Serge Belongie. Feature Pyramid Networks for Object Detection. CVPR 2017.\n",
    ".. [He17] Kaiming He and Georgia Gkioxari and Piotr Dollár and and Ross Girshick. Mask {R-CNN}. ICCV 2017.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluoncv-101",
   "language": "python",
   "name": "gluoncv-101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
